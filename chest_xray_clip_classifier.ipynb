{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twFBrUkeGesB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report\n",
        "from transformers import CLIPProcessor, CLIPModel#150M params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Dataset/Datasetp.csv\")\n",
        "valid_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/valid.csv\")"
      ],
      "metadata": {
        "id": "JPhXC7w8HCn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(valid_df.shape)"
      ],
      "metadata": {
        "id": "Wdx8ho4jHDkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_base_path = \"/content/drive/MyDrive/Dataset/train\"\n",
        "valid_base_path = \"/content/drive/MyDrive/Dataset/valid\""
      ],
      "metadata": {
        "id": "V3JuSBfeHRsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Path'] = df['Path'].apply(lambda x: x.replace(\"CheXpert-v1.0-small/train\", train_base_path))\n",
        "valid_df['Path'] = valid_df['Path'].apply(lambda x: x.replace(\"CheXpert-v1.0-small/valid\", valid_base_path))"
      ],
      "metadata": {
        "id": "phYFj5iJHUkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Path'].apply(os.path.exists).value_counts())\n",
        "print(valid_df['Path'].apply(os.path.exists).value_counts())"
      ],
      "metadata": {
        "id": "aJp6Pi5THaq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images = glob.glob(\"/content/drive/MyDrive/Dataset/train/**/*.jpg\", recursive=True)\n",
        "print(\"Total sample images found:\", len(sample_images))\n",
        "print(sample_images[:5])"
      ],
      "metadata": {
        "id": "rN2X91IdHYgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df[df['Path'].apply(os.path.exists)].reset_index(drop=True)\n",
        "valid_df = valid_df[valid_df['Path'].apply(os.path.exists)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train set after filtering:\", train_df.shape)\n",
        "print(\"Valid set after filtering:\", valid_df.shape)"
      ],
      "metadata": {
        "id": "L5dhc17uHiyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['Sex', 'Age', 'Frontal/Lateral', 'AP/PA',\n",
        "             'Fracture', 'Enlarged Cardiomediastinum',\n",
        "             'Lung Lesion', 'Pleural Other', 'Support Devices']"
      ],
      "metadata": {
        "id": "rSvGAVqbHmnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(columns=drop_cols)\n",
        "valid_df = valid_df.drop(columns=drop_cols)"
      ],
      "metadata": {
        "id": "IDUxto3lHr9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.fillna(0).replace(-1, 0)\n",
        "valid_df = valid_df.fillna(0).replace(-1, 0)"
      ],
      "metadata": {
        "id": "3vdzKeXiHx0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values (train):\")\n",
        "print(train_df.isna().sum())"
      ],
      "metadata": {
        "id": "fqtZYXyyHy4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = [\n",
        "    'No Finding', 'Cardiomegaly', 'Lung Opacity',\n",
        "    'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
        "    'Pneumothorax', 'Pleural Effusion'\n",
        "]"
      ],
      "metadata": {
        "id": "dYVpGesvH2ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[label_cols] = train_df[label_cols].astype(int)"
      ],
      "metadata": {
        "id": "bvprq8C2H6Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "Ki0ghO6lKehi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_templates = {\n",
        "    \"No Finding\": \"No significant abnormality detected.\",\n",
        "    \"Cardiomegaly\": \"Heart appears enlarged.\",\n",
        "    \"Lung Opacity\": \"Opacity observed in the lung region.\",\n",
        "    \"Edema\": \"Fluid accumulation in lungs indicating edema.\",\n",
        "    \"Consolidation\": \"Lung consolidation visible.\",\n",
        "    \"Pneumonia\": \"Opacity in lower lobe suggesting pneumonia.\",\n",
        "    \"Atelectasis\": \"Signs of partial lung collapse (atelectasis).\",\n",
        "    \"Pneumothorax\": \"Air trapped in pleural space suggesting pneumothorax.\",\n",
        "    \"Pleural Effusion\": \"Pleural effusion observed.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZYWTKFqTIAxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(row):\n",
        "    report = [text for col, text in report_templates.items() if row[col] == 1]\n",
        "    if not report:\n",
        "        report.append(\"No abnormal findings observed.\")\n",
        "    return \" \".join(report)\n",
        "\n",
        "train_df['Report'] = train_df.apply(generate_report, axis=1)\n",
        "valid_df['Report'] = valid_df.apply(generate_report, axis=1)"
      ],
      "metadata": {
        "id": "TI1WZ7NGIBvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "ExDsUW0GKj_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"/content/drive/MyDrive/Dataset/Chexpert_train_reports.csv\", index=False)\n",
        "valid_df.to_csv(\"/content/drive/MyDrive/Dataset/Chexpert_valid_reports.csv\", index=False)\n",
        "print(\"Files saved successfully!\")"
      ],
      "metadata": {
        "id": "-CJilJJYIOfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"openai/clip-vit-base-patch32\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "processor = CLIPProcessor.from_pretrained(model_id)#tensor\n",
        "clip = CLIPModel.from_pretrained(model_id).to(device)#embeddings\n",
        "clip.eval()"
      ],
      "metadata": {
        "id": "extIS3PGISuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheXpertCLIPDataset(Dataset):\n",
        "    def __init__(self, df, label_cols):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.label_cols = label_cols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['Path']\n",
        "        report = str(row['Report'])\n",
        "        labels = torch.tensor(row[self.label_cols].values.astype(np.float32), dtype=torch.float32)\n",
        "        return img_path, report, labels"
      ],
      "metadata": {
        "id": "G4JmAIE8IWI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    img_paths, texts, labels = zip(*batch)#list of tuple\n",
        "    images = [Image.open(p).convert(\"RGB\") for p in img_paths]\n",
        "    inputs = processor(text=list(texts), images=images, return_tensors=\"pt\", padding=True)\n",
        "    labels = torch.stack(labels)\n",
        "    return inputs, labels"
      ],
      "metadata": {
        "id": "im3bz5llIW74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CheXpertCLIPDataset(train_df, label_cols)\n",
        "valid_dataset = CheXpertCLIPDataset(valid_df, label_cols)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_batch, num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "pgulPXVYIaI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in clip.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "QmHSLFfBIec6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dim, txt_dim = 512, 512\n",
        "fusion_dim = img_dim + txt_dim"
      ],
      "metadata": {
        "id": "fy4OFtGjIn8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nn.Sequential(\n",
        "    nn.Linear(fusion_dim, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, len(label_cols))\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "elSxwuHCItf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_weights = []\n",
        "for col in label_cols:\n",
        "    n_pos = train_df[col].sum()\n",
        "    n_neg = len(train_df) - n_pos\n",
        "    w1 = (n_neg / n_pos) if n_pos > 0 else 0.0\n",
        "    pos_weights.append(w1)\n",
        "\n",
        "pos_weight = torch.tensor(pos_weights, dtype=torch.float32).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "1XZeYJIGIuVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 6\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    classifier.train()\n",
        "    running_loss = 0.0 #So it is a temporary counter for calculate loss in every epoch.\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} train\"):#8 per trip 509 per epoch, delivery truck, label on bar, unpack item\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outs = clip(**inputs)\n",
        "            img_emb, txt_emb = outs.image_embeds, outs.text_embeds\n",
        "\n",
        "        fused = torch.cat([img_emb, txt_emb], dim=1)\n",
        "        logits = classifier(fused)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # ---- Validation ----\n",
        "    classifier.eval() #test mode, disables droupout,Stable predictions\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():#Skip gradient computation,Saves memory,Faster\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "            labels = labels.to(device)\n",
        "            outs = clip(**inputs)\n",
        "            fused = torch.cat([outs.image_embeds, outs.text_embeds], dim=1)\n",
        "            logits = classifier(fused) #[8, 9] raw scores                  #[8, 1024]\n",
        "            val_loss += criterion(logits, labels).item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(valid_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")#Epoch 1: Train Loss=0.8234, Val Loss=0.7891\n"
      ],
      "metadata": {
        "id": "InnBMkRqI5Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EkAK_bUeJA4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(classifier.state_dict(), \"/content/clip_classifier_head.pt\")\n",
        "print(\"Saved classifier head to /content/clip_classifier_head.pt\")"
      ],
      "metadata": {
        "id": "yCbt9xejJKiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "def show_actual_vs_predicted(df, clip_model, classifier, processor, device, label_names, num_samples=2):\n",
        "    samples = df.sample(num_samples).reset_index(drop=True)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    for i, row in samples.iterrows():\n",
        "        img_path = row['Path']\n",
        "        report_text = row['Report']\n",
        "        actual_labels = [label for label in label_names if row[label] == 1]\n",
        "\n",
        "        # Preprocess\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        inputs = processor(text=[report_text], images=[image], return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            outputs = clip_model(**inputs)\n",
        "            fused = torch.cat([outputs.image_embeds, outputs.text_embeds], dim=1)\n",
        "            logits = classifier(fused)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "        preds_binary = (probs >= 0.5).astype(int)\n",
        "        predicted_labels = [label_names[j] for j, v in enumerate(preds_binary) if v == 1]\n",
        "        if not predicted_labels:\n",
        "            predicted_labels = [\"No Finding\"]\n",
        "\n",
        "        # Plot each image\n",
        "        plt.subplot(1, 2, i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\n",
        "            f\"Actual: {', '.join(actual_labels) if actual_labels else 'No Finding'}\\n\"\n",
        "            f\"Pred: {', '.join(predicted_labels)}\",\n",
        "            fontsize=7\n",
        "        )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Z7htB84uGxrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = [\n",
        "    \"No Finding\", \"Cardiomegaly\", \"Lung Opacity\",\n",
        "    \"Edema\", \"Consolidation\", \"Pneumonia\",\n",
        "    \"Atelectasis\", \"Pneumothorax\", \"Pleural Effusion\"\n",
        "]\n",
        "\n",
        "show_actual_vs_predicted(valid_df, clip, classifier, processor, device, label_names, num_samples=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "gVPhEPrNGexA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}